.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_basic_run_simple_binary_classification.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_basic_run_simple_binary_classification.py:


Simple Binary Classification
============================

This example uses the 'iris' dataset and performs a simple binary
classification using a Support Vector Machine classifier.

.. include:: ../../links.inc


.. code-block:: default

    # Authors: Federico Raimondo <f.raimondo@fz-juelich.de>
    #
    # License: AGPL
    from seaborn import load_dataset
    from julearn import run_cross_validation
    from julearn.utils import configure_logging








Set the logging level to info to see extra information


.. code-block:: default

    configure_logging(level='INFO')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2020-11-11 14:54:02,609 - julearn - INFO - ===== Lib Versions =====
    2020-11-11 14:54:02,609 - julearn - INFO - numpy: 1.19.0
    2020-11-11 14:54:02,609 - julearn - INFO - scipy: 1.5.4
    2020-11-11 14:54:02,609 - julearn - INFO - sklearn: 0.23.2
    2020-11-11 14:54:02,609 - julearn - INFO - pandas: 1.1.4
    2020-11-11 14:54:02,609 - julearn - INFO - julearn: 0.1.0
    2020-11-11 14:54:02,609 - julearn - INFO - ========================





.. code-block:: default

    df_iris = load_dataset('iris')








The dataset has three kind of species. We will keep two to perform a binary
classification.


.. code-block:: default

    df_iris = df_iris[df_iris['species'].isin(['versicolor', 'virginica'])]








As features, we will use the sepal length, width and petal length.
We will try to predict the species.


.. code-block:: default


    X = ['sepal_length', 'sepal_width', 'petal_length']
    y = 'species'
    scores = run_cross_validation(X=X, y=y, data=df_iris, model='svm')

    print(scores['test_score'])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2020-11-11 14:54:02,614 - julearn - INFO - Using default CV
    2020-11-11 14:54:02,614 - julearn - INFO - ==== Input Data ====
    2020-11-11 14:54:02,614 - julearn - INFO - Using dataframe as input
    2020-11-11 14:54:02,614 - julearn - INFO - Features: ['sepal_length', 'sepal_width', 'petal_length']
    2020-11-11 14:54:02,614 - julearn - INFO - Target: species
    2020-11-11 14:54:02,614 - julearn - INFO - Expanded X: ['sepal_length', 'sepal_width', 'petal_length']
    2020-11-11 14:54:02,614 - julearn - INFO - Expanded Confounds: []
    2020-11-11 14:54:02,615 - julearn - INFO - ====================
    2020-11-11 14:54:02,616 - julearn - INFO - 
    2020-11-11 14:54:02,616 - julearn - INFO - ====== Model ======
    2020-11-11 14:54:02,616 - julearn - INFO - Obtaining model by name: svm
    2020-11-11 14:54:02,616 - julearn - INFO - ===================
    2020-11-11 14:54:02,616 - julearn - INFO - 
    2020-11-11 14:54:02,616 - julearn - INFO - CV interpeted as RepeatedKFold with 5 repetitions of 5 folds
    [0.95 0.8  0.95 0.9  0.9  0.9  1.   0.85 0.9  0.9  0.95 0.95 0.9  1.
     0.8  0.95 0.8  0.95 0.95 0.9  0.9  0.95 0.85 0.9  0.95]




Additionaly, we can choose to assess the performance of the model using
different scoring functions.

For example, we might have an unbalanced dataset:


.. code-block:: default


    df_unbalanced = df_iris[20:]  # drop the first 20 versicolor samples
    print(df_unbalanced['species'].value_counts())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    virginica     50
    versicolor    30
    Name: species, dtype: int64




If we compute the `accuracy`, we might not account for this imbalance. A more
suitable metric is the `balanced_accuracy`. More information in scikit-learn:
`Balanced Accuracy`_

We will also set the random seed so we always split the data in the same way.


.. code-block:: default

    scores = run_cross_validation(
        X=X, y=y, data=df_unbalanced, model='svm', seed=42,
        scoring=['accuracy', 'balanced_accuracy'])

    print(scores['test_accuracy'].mean())
    print(scores['test_balanced_accuracy'].mean())






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2020-11-11 14:54:03,061 - julearn - INFO - Setting random seed to 42
    2020-11-11 14:54:03,061 - julearn - INFO - Using default CV
    2020-11-11 14:54:03,061 - julearn - INFO - ==== Input Data ====
    2020-11-11 14:54:03,061 - julearn - INFO - Using dataframe as input
    2020-11-11 14:54:03,061 - julearn - INFO - Features: ['sepal_length', 'sepal_width', 'petal_length']
    2020-11-11 14:54:03,061 - julearn - INFO - Target: species
    2020-11-11 14:54:03,061 - julearn - INFO - Expanded X: ['sepal_length', 'sepal_width', 'petal_length']
    2020-11-11 14:54:03,061 - julearn - INFO - Expanded Confounds: []
    2020-11-11 14:54:03,062 - julearn - INFO - ====================
    2020-11-11 14:54:03,063 - julearn - INFO - 
    2020-11-11 14:54:03,063 - julearn - INFO - ====== Model ======
    2020-11-11 14:54:03,063 - julearn - INFO - Obtaining model by name: svm
    2020-11-11 14:54:03,063 - julearn - INFO - ===================
    2020-11-11 14:54:03,063 - julearn - INFO - 
    2020-11-11 14:54:03,063 - julearn - INFO - CV interpeted as RepeatedKFold with 5 repetitions of 5 folds
    0.895
    0.8708886668886668




Other kind of metrics allows us to evaluate how good our model is to detect
specific targets. Suppose we want to create a model that correctly identifies
the `versicolor` samples.

Now we might want to evaluate the precision score, or the ratio of true
positives (tp) over all positives (true and false positives). More
information in scikit-learn: `Precision`_

For this metric to work, we need to define which are our `positive` values.
In this example, we are interested in detecting `versicolor`.


.. code-block:: default

    precision_scores = run_cross_validation(
        X=X, y=y, data=df_unbalanced, model='svm', seed=42,
        scoring='precision', pos_labels='versicolor')
    print(precision_scores['test_precision'].mean())




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2020-11-11 14:54:03,684 - julearn - INFO - Setting random seed to 42
    2020-11-11 14:54:03,684 - julearn - INFO - Using default CV
    2020-11-11 14:54:03,685 - julearn - INFO - ==== Input Data ====
    2020-11-11 14:54:03,685 - julearn - INFO - Using dataframe as input
    2020-11-11 14:54:03,685 - julearn - INFO - Features: ['sepal_length', 'sepal_width', 'petal_length']
    2020-11-11 14:54:03,685 - julearn - INFO - Target: species
    2020-11-11 14:54:03,685 - julearn - INFO - Expanded X: ['sepal_length', 'sepal_width', 'petal_length']
    2020-11-11 14:54:03,685 - julearn - INFO - Expanded Confounds: []
    2020-11-11 14:54:03,686 - julearn - INFO - Setting the following as positive labels ['versicolor']
    2020-11-11 14:54:03,686 - julearn - INFO - ====================
    2020-11-11 14:54:03,686 - julearn - INFO - 
    2020-11-11 14:54:03,687 - julearn - INFO - ====== Model ======
    2020-11-11 14:54:03,687 - julearn - INFO - Obtaining model by name: svm
    2020-11-11 14:54:03,687 - julearn - INFO - ===================
    2020-11-11 14:54:03,687 - julearn - INFO - 
    2020-11-11 14:54:03,687 - julearn - INFO - CV interpeted as RepeatedKFold with 5 repetitions of 5 folds
    0.9223333333333333





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.567 seconds)


.. _sphx_glr_download_auto_examples_basic_run_simple_binary_classification.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: run_simple_binary_classification.py <run_simple_binary_classification.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: run_simple_binary_classification.ipynb <run_simple_binary_classification.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/advanced/dis_run_return_confounds.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_advanced_dis_run_return_confounds.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_advanced_dis_run_return_confounds.py:


Return Confounds in Confound Removal
====================================

In most cases confound removal is a simple operation.
You regress out the confound from the features and only continue working with
these new confound removed features. This is also the default setting for
julearn's `remove_confound` step. But sometimes you want to work with the
confound even after removing it from the features. In this example, we
will discuss the options you have.

.. include:: ../../links.inc

.. GENERATED FROM PYTHON SOURCE LINES 14-26

.. code-block:: default

    # Authors: Sami Hamdan <s.hamdan@fz-juelich.de>
    #
    # License: AGPL
    from sklearn.datasets import load_diabetes  # to load data
    from julearn.transformers import ChangeColumnTypes
    from julearn import run_cross_validation
    import warnings

    # load in the data
    df_features, target = load_diabetes(return_X_y=True, as_frame=True)



.. GENERATED FROM PYTHON SOURCE LINES 27-33

First, we can have a look at our features.
You can see it includes
Age, BMI, average blood pressure (bp) and 6 other measures from s1 to s6
Furthermore, it includes sex which will be considered as a confound in
this example.


.. GENERATED FROM PYTHON SOURCE LINES 33-35

.. code-block:: default

    print('Features: ', df_features.head())


.. GENERATED FROM PYTHON SOURCE LINES 36-37

Second, we can have a look at the target

.. GENERATED FROM PYTHON SOURCE LINES 37-39

.. code-block:: default

    print('Target: ', target.describe())


.. GENERATED FROM PYTHON SOURCE LINES 40-41

Now, we can put both into one DataFrame:

.. GENERATED FROM PYTHON SOURCE LINES 41-44

.. code-block:: default

    data = df_features.copy()
    data['target'] = target


.. GENERATED FROM PYTHON SOURCE LINES 45-55

In the following we will explore different settings of confound removal
using Julearns pipeline functionalities.

Confound Removal Typical Use Case
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Here, we want to deconfound the features and not include the confound as a
feature into our last model.
Afterwards, we will transform our features with a pca and run
a linear regression.


.. GENERATED FROM PYTHON SOURCE LINES 55-64

.. code-block:: default

    feature_names = list(df_features.drop(columns='sex').columns)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", lineno=443)
        scores, model = run_cross_validation(
            X=feature_names, y='target', data=data,
            confounds='sex', model='linreg', problem_type='regression',
            preprocess_X=['remove_confound', 'pca'],
            return_estimator='final')


.. GENERATED FROM PYTHON SOURCE LINES 65-71

We can use the `preprocess` method of the `.ExtendedDataFramePipeline`
to inspect the transformations/preprocessing steps of the returned estimator.
By providing a step name to the `until` argument of the
`preprocess` method we return the transformed X and y up to
the provided step (inclusive).
This output consists of a tuple containing the transformed X and y,

.. GENERATED FROM PYTHON SOURCE LINES 71-87

.. code-block:: default

    X_deconfounded, _ = model.preprocess(
        df_features, target, until='remove_confound')
    print(X_deconfounded.head())

    # As you can see the confound `sex` was dropped
    # and only the confound removed features are used in the following pca.
    # But what if you want to keep the confound after removal for
    # other transformations.
    #
    # For example, let's assume that you want to do a pca on the confound removed
    # feature, but want to keep the confound for the actual modelling step.
    # Let us have a closer look to the confound remover in order to understand
    # how we could achieve such a task:
    #
    # .. autoclass:: julearn.transformers.DataFrameConfoundRemover


.. GENERATED FROM PYTHON SOURCE LINES 88-91

Above, you can see that we can set the `keep_confounds` argument to True.
This will keep the confounds after confound removal.
Here, is an example of how this can look like:

.. GENERATED FROM PYTHON SOURCE LINES 91-99

.. code-block:: default


    scores, model = run_cross_validation(
        X=feature_names, y='target', data=data,
        confounds='sex', model='linreg', problem_type='regression',
        preprocess_X=['remove_confound', 'pca'],
        model_params=dict(remove_confound__keep_confounds=True),
        return_estimator='final')


.. GENERATED FROM PYTHON SOURCE LINES 100-101

As you can see this will keep the confound

.. GENERATED FROM PYTHON SOURCE LINES 101-105

.. code-block:: default

    X_deconfounded, _ = model.preprocess(
        df_features, target, until='remove_confound')
    print(X_deconfounded.head())


.. GENERATED FROM PYTHON SOURCE LINES 106-110

Even after the pca the confound will still be present.
This is the case because by default transformers only transform continuous
features (including features without a specified type)
and ignore confounds and categorical variables.

.. GENERATED FROM PYTHON SOURCE LINES 110-116

.. code-block:: default

    X_transformed, _ = model.preprocess(df_features, target)
    print(X_transformed.head())

    # This means that the resulting Linear Regression will use the deconfounded
    # features together with the confound to predict the target.


.. GENERATED FROM PYTHON SOURCE LINES 117-122

Lastly, you can also use the confound as a normal feature after confound
removal. To do so you can either add the confound(s) to the
which return the same columns or you can use the
`.ChangeColumnTypes` to change the returned confounds
to a continuous variable like this:

.. GENERATED FROM PYTHON SOURCE LINES 122-134

.. code-block:: default

    scores, model = run_cross_validation(
        X=feature_names, y='target', data=data,
        confounds='sex', model='linreg', problem_type='regression',
        preprocess_X=['remove_confound',
                      ChangeColumnTypes('.*confound', 'continuous'),
                      'pca'],
        preprocess_confounds='zscore',
        model_params=dict(remove_confound__keep_confounds=True),
        return_estimator='final'
    )



.. GENERATED FROM PYTHON SOURCE LINES 135-137

As you can see this will keep the confound and
change its type to a continuous variable.

.. GENERATED FROM PYTHON SOURCE LINES 137-142

.. code-block:: default

    X_deconfounded, _ = model.preprocess(
        df_features, target, until='changecolumntypes',
        return_trans_column_type=True)
    print(X_deconfounded.head())


.. GENERATED FROM PYTHON SOURCE LINES 143-145

Because the confound is treated as a normal continuous feature
after removal it will be transformed in the pca as well

.. GENERATED FROM PYTHON SOURCE LINES 145-147

.. code-block:: default

    X_transformed, _ = model.preprocess(df_features, target)
    print(X_transformed.head())


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_auto_examples_advanced_dis_run_return_confounds.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: dis_run_return_confounds.py <dis_run_return_confounds.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: dis_run_return_confounds.ipynb <dis_run_return_confounds.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

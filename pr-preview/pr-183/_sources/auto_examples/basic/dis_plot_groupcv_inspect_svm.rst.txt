
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/basic/dis_plot_groupcv_inspect_svm.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_basic_dis_plot_groupcv_inspect_svm.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_basic_dis_plot_groupcv_inspect_svm.py:


Inspecting SVM models
=====================

This example uses the 'fmri' dataset, performs simple binary classification
using a Support Vector Machine classifier and analyse the model.

References
----------
Waskom, M.L., Frank, M.C., Wagner, A.D. (2016). Adaptive engagement of
cognitive control in context-dependent decision-making. Cerebral Cortex.


.. include:: ../../links.inc

.. GENERATED FROM PYTHON SOURCE LINES 16-34

.. code-block:: default

    # Authors: Federico Raimondo <f.raimondo@fz-juelich.de>
    #          Shammi More <s.more@fz-juelich.de>
    #
    # License: AGPL

    import numpy as np
    import pandas as pd

    from sklearn.model_selection import GroupShuffleSplit

    import matplotlib.pyplot as plt
    import seaborn as sns
    from seaborn import load_dataset

    from julearn import run_cross_validation
    from julearn.utils import configure_logging
    from julearn.inspect import preprocess


.. GENERATED FROM PYTHON SOURCE LINES 35-36

Set the logging level to info to see extra information

.. GENERATED FROM PYTHON SOURCE LINES 36-39

.. code-block:: default

    configure_logging(level='INFO')



.. GENERATED FROM PYTHON SOURCE LINES 40-43

Dealing with Cross-Validation techniques
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


.. GENERATED FROM PYTHON SOURCE LINES 43-46

.. code-block:: default


    df_fmri = load_dataset('fmri')


.. GENERATED FROM PYTHON SOURCE LINES 47-49

First, lets get some information on what the dataset has:


.. GENERATED FROM PYTHON SOURCE LINES 49-51

.. code-block:: default

    print(df_fmri.head())


.. GENERATED FROM PYTHON SOURCE LINES 52-57

From this information, we can infer that it is an fMRI study in which there
were several subjects, timepoints, events and signal extracted from several
brain regions.

Lets check how many kinds of each we have.

.. GENERATED FROM PYTHON SOURCE LINES 57-63

.. code-block:: default


    print(df_fmri['event'].unique())
    print(df_fmri['region'].unique())
    print(sorted(df_fmri['timepoint'].unique()))
    print(df_fmri['subject'].unique())


.. GENERATED FROM PYTHON SOURCE LINES 64-67

We have data from parietal and frontal regions during 2 types of events
(*cue* and *stim*) during 18 timepoints and for 14 subjects.
Lets see how many samples we have for each condition

.. GENERATED FROM PYTHON SOURCE LINES 67-72

.. code-block:: default


    print(df_fmri.groupby(['subject', 'timepoint', 'event', 'region']).count())
    print(np.unique(df_fmri.groupby(
        ['subject', 'timepoint', 'event', 'region']).count().values))


.. GENERATED FROM PYTHON SOURCE LINES 73-79

We have exactly one value per condition.

Lets try to build a model, that uses parietal and frontal signal to predicts
whether the event was a *cue* or a *stim*.

First we define our X and y variables.

.. GENERATED FROM PYTHON SOURCE LINES 79-82

.. code-block:: default

    X = ['parietal', 'frontal']
    y = 'event'


.. GENERATED FROM PYTHON SOURCE LINES 83-88

In order for this to work, both *parietal* and *frontal* must be columns.
We need to *pivot* the table.

The values of *region* will be the columns. The column *signal* will be the
values. And the columns *subject*, *timepoint* and *event* will be the index

.. GENERATED FROM PYTHON SOURCE LINES 88-95

.. code-block:: default

    df_fmri = df_fmri.pivot(
        index=['subject', 'timepoint', 'event'],
        columns='region',
        values='signal')

    df_fmri = df_fmri.reset_index()


.. GENERATED FROM PYTHON SOURCE LINES 96-98

Here we want to zscore all the features and then train a Support Vector
Machine classifier.

.. GENERATED FROM PYTHON SOURCE LINES 98-104

.. code-block:: default


    scores = run_cross_validation(X=X, y=y, data=df_fmri, preprocess='zscore',
                                  model='svm')

    print(scores['test_score'].mean())


.. GENERATED FROM PYTHON SOURCE LINES 105-126

This results indicate that we can decode the kind of event by looking at
the *parietal* and *frontal* signal. However, that claim is true only if we
have some data from the same subject already acquired.

The problem is that we split the data randomly into 5 folds (default, see
:func:`.run_cross_validation`). This means that data from one subject could
be both in the training and the testing set. If this is the case, then the
model can learn the subjects' specific characteristics and apply it to the
testing set. Thus, it is not true that we can decode it for an unseen
subject, but for an unseen timepoint for a subject that for whom we already
have data.

To test for unseen subject, we need to make sure that all the data from each
subject is either on the training or the testing set, but not in both.

We can use scikit-learn's GroupShuffleSplit (see `Cross Validation`_).
And specify which is the grouping column using the `group` parameter.

By setting `return_estimator='final'`, the :func:`.run_cross_validation`
function return the estimator fitted with all the data. We will use this
later to do some analysis.

.. GENERATED FROM PYTHON SOURCE LINES 126-134

.. code-block:: default

    cv = GroupShuffleSplit(n_splits=5, test_size=0.5, random_state=42)

    scores, model = run_cross_validation(
        X=X, y=y, data=df_fmri, preprocess='zscore', model='svm', cv=cv,
        groups='subject', return_estimator='final')

    print(scores['test_score'].mean())


.. GENERATED FROM PYTHON SOURCE LINES 135-140

After testing on independent subjects, we can now claim that given a new
subject, we can predict the kind of event.

Lets do some visualization on how these two features interact and what
the preprocessing part of the model does.

.. GENERATED FROM PYTHON SOURCE LINES 140-159

.. code-block:: default


    # Plot the raw features
    fig, axes = plt.subplots(1, 2, figsize=(8, 4))
    sns.scatterplot(x='parietal', y='frontal', hue='event', data=df_fmri,
                    ax=axes[0], s=5)
    axes[0].set_title('Raw data')

    # Plot the preprocessed features
    pre_X = preprocess(model, X=X, data=df_fmri, until="zscore",
                       with_column_types=True)

    pre_df = pre_X.join(df_fmri[y])

    sns.scatterplot(
        x='parietal__:type:__continuous', y='frontal__:type:__continuous',
        hue='event', data=pre_df, ax=axes[1], s=5)

    axes[1].set_title('Preprocessed data')


.. GENERATED FROM PYTHON SOURCE LINES 160-164

In this case, the preprocessing is nothing more than a `Standard Scaler`_.

It seems that the data is not quite linearly separable. Lets now visualize
how the SVM does this complex task.

.. GENERATED FROM PYTHON SOURCE LINES 164-189

.. code-block:: default


    # get the model from the pipeline
    clf = model[2]
    fig = plt.figure()
    ax = sns.scatterplot(
        x='parietal__:type:__continuous', y='frontal__:type:__continuous',
        hue='event', data=pre_df, s=5)

    xlim = ax.get_xlim()
    ylim = ax.get_ylim()

    # create grid to evaluate model
    xx = np.linspace(xlim[0], xlim[1], 30)
    yy = np.linspace(ylim[0], ylim[1], 30)
    YY, XX = np.meshgrid(yy, xx)
    xy = np.vstack([XX.ravel(), YY.ravel()]).T

    # Create pandas dataframe
    xy_df = pd.DataFrame(
        data=xy,
        columns=['parietal__:type:__continuous', 'frontal__:type:__continuous'])

    Z = clf.decision_function(xy_df).reshape(XX.shape)
    a = ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-'])
    ax.set_title('Preprocessed data with SVM decision function boundaries')


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_auto_examples_basic_dis_plot_groupcv_inspect_svm.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: dis_plot_groupcv_inspect_svm.py <dis_plot_groupcv_inspect_svm.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: dis_plot_groupcv_inspect_svm.ipynb <dis_plot_groupcv_inspect_svm.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
